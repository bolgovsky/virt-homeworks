# Домашнее задание к занятию "6.6. Troubleshooting"

---

В данном файле приведены **только ответы** ! Т.е. можно искать по **Ответ:**

---

## Задача 1

Перед выполнением задания ознакомьтесь с документацией по [администрированию MongoDB](https://docs.mongodb.com/manual/administration/).

Пользователь (разработчик) написал в канал поддержки, что у него уже 3 минуты происходит CRUD операция в MongoDB и её 
нужно прервать. 

Вы как инженер поддержки решили произвести данную операцию:
- напишите список операций, которые вы будете производить для остановки запроса пользователя

**Ответ:** вначале найдем все CRUD операции текущего пользователя, длительностью больше 180 секунд:
```json
db.currentOp(
    {
        "op" : { "$in" : [  "aggregate", "count", "delete", "distinct", "find", "findAndModify", "getMore", "insert", "mapReduce", "update" ] } ,
        "secs_running" : { "$gt" : 180 },
        "$ownOp" : 1 
    }
)
```
В ответе найдем нужные нам '"opid" : <number>' запросов и используем db.killOp(<opId>) для завершения проблемных запросов.

- предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB
**Ответ:** использовать метод maxTimeMS(), чтобы установить ограничение по времени (в миллисекундах) для операции(для потенциально проблемных или выявленно проблемных операций клиента). 
Когда операция достигает указанного срока, MongoDB прерывает операцию в следующей точке прерывания.

---

Для себя:

Например:
```json
db.location.find( { "town": { "$regex": "(Pine Lumber)",
                              "$options": 'i' } } ).maxTimeMS(30)
```

db.getLastError()и db.getLastErrorObj()вернет ошибки для прерванных опций:

```json
{ "n" : 0,
  "connectionId" : 1,
  "err" : "operation exceeded time limit",
  "ok" : 1 }
```
ПРЕДУПРЕЖДЕНИЕ
Прекращайте текущие операции с особой осторожностью. Используйте только db.killOp()для завершения операций, инициированных клиентами, и не завершайте внутренние операции базы данных.

---

## Задача 2

Перед выполнением задания познакомьтесь с документацией по [Redis latency troobleshooting](https://redis.io/topics/latency).

Вы запустили инстанс Redis для использования совместно с сервисом, который использует механизм TTL. 
Причем отношение количества записанных key-value значений к количеству истёкших значений есть величина постоянная и
увеличивается пропорционально количеству реплик сервиса. 

При масштабировании сервиса до N реплик вы увидели, что:
- сначала рост отношения записанных значений к истекшим
- Redis блокирует операции записи

Как вы думаете, в чем может быть проблема?
 
**Ответ:** практически с Redis не сталкивался, поэтому пишу ответ согласно документации и собственных измышлений:

1. Причиной может быть использование медленных команд. Так как Redis однопоточный(последовательно выполняет команды),
то использование команд, работающих со многими элементами, например 'SORT', 'LREM', 'SUNIONи' других (в документации 
отмечено использование 'KEYS' как ОЧЕНЬ частой причины задержки)  могут привести к значительным задержкам, особенно 
учитывая масштабирование сервиса. 

**Выход** - максимально исключить использование такого рода команд и мониторинг времени их выполнения.

2. Задержка из-за AOF и дискового ввода-вывода. Redis использует механизм Append Of File (AOF), который , в свою очередь , 
использует системные вызовы  'write(2)'- для записи данных в AOF  и 'fdatasync(2)' - для очистки буфера файла ядра на диске.
Таким образом будет возникать значительная задержка(блокировка):
* 'write(2)' блокируется при общесистемной синхронизации и при переполнении выходных буфферов в ожидании очистки диска для 
возможности принять новые записи
* 'fdatasync(2)' может блокироваться при наличии других процессов ввода-вывода или при совместном использовании с 
'write(2)' - у них определенный порядок взаимодействия.

**Выход** - грамотное изначальное или гибкое изменение параметра конфигурации 'appendfsync' для 'fdatasync(2)'

3. Задержка, вызванная истечением срока действия ключей, точнее - механизмом удаления ключей с истекшим сроком действия
(lazzy way и active way ). То есть "если в базе данных есть много ключей, срок действия которых истекает в одну и ту же
секунду, и они составляют не менее 25% текущей совокупности ключей с установленным сроком действия , Redis может 
заблокировать, чтобы получить процент ключей, срок действия которых истек ниже, чем 25%" (чтобы не использовать слишком
много памяти для истекших ключей).

**Выход** - превентивное отслеживание процента истекших ключей.

---

## Задача 3

Перед выполнением задания познакомьтесь с документацией по [Common Mysql errors](https://dev.mysql.com/doc/refman/8.0/en/common-errors.html).

Вы подняли базу данных MySQL для использования в гис-системе. При росте количества записей, в таблицах базы,
пользователи начали жаловаться на ошибки вида:
```python
InterfaceError: (InterfaceError) 2013: Lost connection to MySQL server during query u'SELECT..... '
```

Как вы думаете, почему это начало происходить и как локализовать проблему?

**Ответ:** тут явный 'select' "в бесконечность", то есть начинают тянуться какие-то нереальные объемы данных, которые 
не могут дойти до клиента по сетевому тайм-ауту 'net_read_timeout '.
Локализовать проблему поможет включение 'slow_log' в конфигурации 'mysqld' c последующим просмотром логов либо использование 
директивы 'EXPLAIN'.
 
Какие пути решения данной проблемы вы можете предложить?

**Ответ:** 
1. Увеличивать 'net_read_timeout ' до поры, пока запросы не начнут проходить.
2. Скорректировать требования к пользовательским операциям 'CRUD', в первую очередь 'select'(тянуть меньше данных). Этот вариант , 
как правило, является предпочтительным, если не ОСНОВНЫМ.

---

## Задача 4

Перед выполнением задания ознакомтесь со статьей [Common PostgreSQL errors](https://www.percona.com/blog/2020/06/05/10-common-postgresql-errors/) из блога Percona.

Вы решили перевести гис-систему из задачи 3 на PostgreSQL, так как прочитали в документации, что эта СУБД работает с 
большим объемом данных лучше, чем MySQL.

После запуска пользователи начали жаловаться, что СУБД время от времени становится недоступной. В dmesg вы видите, что:

`postmaster invoked oom-killer`

Как вы думаете, что происходит?

**Ответ:** нехватка ресурсов (памяти или свопа) - при попытке выделения памяти для процесса 'postmaster' стало ясно, что
памяти не хватает и процесс 'oom-killer' завершил процесс `postmaster'. 

Как бы вы решили данную проблему?

**Ответ:** 
Причин может быть масса: "соседство" с другими приложениями, большое количество сетевых соединений(незакрытых), невыполнение п.2 из
предыдущего ответа(очень похоже), недостаточное количество ОЗУ и/или свопа для работы и прочее.

В-любом случае нам необходимо настроить PostgreSQL согласно рекомендациям из 'best practice', включить мониторинг запросов 
и отследить жор ресурса. 
Дальше: тюнить СУБД(ограничивать количество сетевых соединений), скорректировать требования к пользовательским операциям 
'CRUD', разносить приложения, увеличивать ОЗУ и своп(вертикально масштабировать), тюнить параметры 'oom-killer' либо отключить
его для процесса СУБД (но так делать не надо).


            